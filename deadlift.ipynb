{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate the model\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,image = cap.read()\n",
    "        # Recolor the feed\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recoloring the image back for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS\n",
    "                                  , mp_drawing.DrawingSpec(color=(245,117,66),thickness=2,circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230),thickness=2,circle_radius=2))\n",
    "        \n",
    "        cv2.imshow('Raw Cam Feed',image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "cap = cv2.VideoCapture(0)\n",
    "time.sleep(5)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc('P','I','M','1')\n",
    "videoWriter = cv2.VideoWriter('press.avi',fourcc,fps,(int(width),int(height)))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    try:\n",
    "        cv2.imshow('Press',frame)\n",
    "        videoWriter.write(frame)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "videoWriter.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturing Landmarks and Saving it to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'x1',\n",
       " 'y1',\n",
       " 'z1',\n",
       " 'v1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'z2',\n",
       " 'v2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'z3',\n",
       " 'v3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'z4',\n",
       " 'v4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'z5',\n",
       " 'v5',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'z6',\n",
       " 'v6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'z7',\n",
       " 'v7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'z8',\n",
       " 'v8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'z9',\n",
       " 'v9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'z10',\n",
       " 'v10',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'z11',\n",
       " 'v11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'z12',\n",
       " 'v12',\n",
       " 'x13',\n",
       " 'y13',\n",
       " 'z13',\n",
       " 'v13',\n",
       " 'x14',\n",
       " 'y14',\n",
       " 'z14',\n",
       " 'v14',\n",
       " 'x15',\n",
       " 'y15',\n",
       " 'z15',\n",
       " 'v15',\n",
       " 'x16',\n",
       " 'y16',\n",
       " 'z16',\n",
       " 'v16',\n",
       " 'x17',\n",
       " 'y17',\n",
       " 'z17',\n",
       " 'v17',\n",
       " 'x18',\n",
       " 'y18',\n",
       " 'z18',\n",
       " 'v18',\n",
       " 'x19',\n",
       " 'y19',\n",
       " 'z19',\n",
       " 'v19',\n",
       " 'x20',\n",
       " 'y20',\n",
       " 'z20',\n",
       " 'v20',\n",
       " 'x21',\n",
       " 'y21',\n",
       " 'z21',\n",
       " 'v21',\n",
       " 'x22',\n",
       " 'y22',\n",
       " 'z22',\n",
       " 'v22',\n",
       " 'x23',\n",
       " 'y23',\n",
       " 'z23',\n",
       " 'v23',\n",
       " 'x24',\n",
       " 'y24',\n",
       " 'z24',\n",
       " 'v24',\n",
       " 'x25',\n",
       " 'y25',\n",
       " 'z25',\n",
       " 'v25',\n",
       " 'x26',\n",
       " 'y26',\n",
       " 'z26',\n",
       " 'v26',\n",
       " 'x27',\n",
       " 'y27',\n",
       " 'z27',\n",
       " 'v27',\n",
       " 'x28',\n",
       " 'y28',\n",
       " 'z28',\n",
       " 'v28',\n",
       " 'x29',\n",
       " 'y29',\n",
       " 'z29',\n",
       " 'v29',\n",
       " 'x30',\n",
       " 'y30',\n",
       " 'z30',\n",
       " 'v30',\n",
       " 'x31',\n",
       " 'y31',\n",
       " 'z31',\n",
       " 'v31',\n",
       " 'x32',\n",
       " 'y32',\n",
       " 'z32',\n",
       " 'v32',\n",
       " 'x33',\n",
       " 'y33',\n",
       " 'z33',\n",
       " 'v33']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks = ['class']  # Class is Y - target value\n",
    "for val in range(1,33+1):\n",
    "    landmarks+=['x{}'.format(val),'y{}'.format(val),'z{}'.format(val),'v{}'.format(val)]\n",
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x: 0.54445004\n",
       "y: 0.76619136\n",
       "z: -0.86532974\n",
       "visibility: 0.99935806\n",
       ", x: 0.5631237\n",
       "y: 0.715592\n",
       "z: -0.80185336\n",
       "visibility: 0.9995098\n",
       ", x: 0.5744122\n",
       "y: 0.7153006\n",
       "z: -0.8022639\n",
       "visibility: 0.9994867\n",
       ", x: 0.5846735\n",
       "y: 0.7161993\n",
       "z: -0.8022941\n",
       "visibility: 0.99947447\n",
       ", x: 0.52297485\n",
       "y: 0.7184107\n",
       "z: -0.80494386\n",
       "visibility: 0.99942946\n",
       ", x: 0.50887084\n",
       "y: 0.7192019\n",
       "z: -0.80504143\n",
       "visibility: 0.99936354\n",
       ", x: 0.49542508\n",
       "y: 0.72105664\n",
       "z: -0.805322\n",
       "visibility: 0.9993541\n",
       ", x: 0.5996049\n",
       "y: 0.7439452\n",
       "z: -0.3944849\n",
       "visibility: 0.99966115\n",
       ", x: 0.47565198\n",
       "y: 0.74595517\n",
       "z: -0.4047187\n",
       "visibility: 0.99947\n",
       ", x: 0.56953084\n",
       "y: 0.8215501\n",
       "z: -0.7103702\n",
       "visibility: 0.99920714\n",
       ", x: 0.52072847\n",
       "y: 0.8186177\n",
       "z: -0.7159082\n",
       "visibility: 0.9991791\n",
       ", x: 0.72457564\n",
       "y: 0.99136907\n",
       "z: -0.22541451\n",
       "visibility: 0.98330843\n",
       ", x: 0.3550369\n",
       "y: 0.9860708\n",
       "z: -0.15153724\n",
       "visibility: 0.95749277\n",
       ", x: 0.828848\n",
       "y: 1.2280537\n",
       "z: -0.77802294\n",
       "visibility: 0.5214461\n",
       ", x: 0.24171522\n",
       "y: 1.2370503\n",
       "z: -0.65491694\n",
       "visibility: 0.38642663\n",
       ", x: 0.7543887\n",
       "y: 1.0622444\n",
       "z: -1.411959\n",
       "visibility: 0.61061203\n",
       ", x: 0.23667936\n",
       "y: 1.0713001\n",
       "z: -1.5447608\n",
       "visibility: 0.38562575\n",
       ", x: 0.74177504\n",
       "y: 1.0219073\n",
       "z: -1.5374451\n",
       "visibility: 0.626865\n",
       ", x: 0.18322837\n",
       "y: 1.02895\n",
       "z: -1.6956186\n",
       "visibility: 0.42890775\n",
       ", x: 0.7076069\n",
       "y: 0.97575897\n",
       "z: -1.4941523\n",
       "visibility: 0.68684864\n",
       ", x: 0.20938346\n",
       "y: 1.0065402\n",
       "z: -1.6695535\n",
       "visibility: 0.5070331\n",
       ", x: 0.706409\n",
       "y: 0.982912\n",
       "z: -1.4148088\n",
       "visibility: 0.6139707\n",
       ", x: 0.21975084\n",
       "y: 1.0155371\n",
       "z: -1.5641143\n",
       "visibility: 0.4549181\n",
       ", x: 0.65496945\n",
       "y: 1.6449158\n",
       "z: -0.056023102\n",
       "visibility: 0.0038971936\n",
       ", x: 0.43690485\n",
       "y: 1.6502784\n",
       "z: 0.060073674\n",
       "visibility: 0.0032993942\n",
       ", x: 0.653679\n",
       "y: 1.9839301\n",
       "z: -0.32478184\n",
       "visibility: 0.023098197\n",
       ", x: 0.4426783\n",
       "y: 2.010922\n",
       "z: -0.31604046\n",
       "visibility: 0.010071923\n",
       ", x: 0.68722236\n",
       "y: 2.4787438\n",
       "z: -0.038530774\n",
       "visibility: 0.0006459897\n",
       ", x: 0.5057747\n",
       "y: 2.473599\n",
       "z: -0.16680741\n",
       "visibility: 0.00034513755\n",
       ", x: 0.69252694\n",
       "y: 2.5638068\n",
       "z: -0.03907745\n",
       "visibility: 0.0003454083\n",
       ", x: 0.5145129\n",
       "y: 2.5473258\n",
       "z: -0.17027184\n",
       "visibility: 0.0003638263\n",
       ", x: 0.6741131\n",
       "y: 2.6007292\n",
       "z: -0.4964581\n",
       "visibility: 0.0013764532\n",
       ", x: 0.53289783\n",
       "y: 2.6011548\n",
       "z: -0.64318115\n",
       "visibility: 0.0015060965\n",
       "]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pose_landmarks.landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords.csv',mode='w',newline='') as f:\n",
    "    csv_writer = csv.writer(f,delimiter=',',quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for exporting the landmarks to train\n",
    "def export_landmark(results,action):\n",
    "    try:\n",
    "        keypoints = np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten()\n",
    "        keypoints = np.insert(keypoints,0,action)\n",
    "\n",
    "        with open('coords.csv',mode='a',newline='') as f: # a stands for append\n",
    "            csv_writer = csv.writer(f,delimiter=',',quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(keypoints)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 13] Permission denied: 'coords.csv'\n"
     ]
    }
   ],
   "source": [
    "export_landmark(results,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m ret,image \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Recolor the feed\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Make Detections\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('press.avi')\n",
    "# initiate the holistic model\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,image = cap.read()\n",
    "        # Recolor the feed\n",
    "        if image is None: break\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recoloring the image back for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS\n",
    "                                  , mp_drawing.DrawingSpec(color=(245,117,66),thickness=2,circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230),thickness=2,circle_radius=2))\n",
    "        \n",
    "        k = cv2.waitKey(1)\n",
    "        if k==117:# u key\n",
    "            export_landmark(results,1)\n",
    "        if k==100:# d key\n",
    "            export_landmark(results,0)\n",
    "\n",
    "        cv2.imshow('Raw Cam Feed',image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the labelled Data on a Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z31</th>\n",
       "      <th>v31</th>\n",
       "      <th>x32</th>\n",
       "      <th>y32</th>\n",
       "      <th>z32</th>\n",
       "      <th>v32</th>\n",
       "      <th>x33</th>\n",
       "      <th>y33</th>\n",
       "      <th>z33</th>\n",
       "      <th>v33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559477</td>\n",
       "      <td>0.801142</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>0.999172</td>\n",
       "      <td>0.570418</td>\n",
       "      <td>0.778712</td>\n",
       "      <td>-0.921206</td>\n",
       "      <td>0.999481</td>\n",
       "      <td>0.578074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304162</td>\n",
       "      <td>0.063764</td>\n",
       "      <td>0.549590</td>\n",
       "      <td>0.864951</td>\n",
       "      <td>0.326376</td>\n",
       "      <td>0.081902</td>\n",
       "      <td>0.595412</td>\n",
       "      <td>0.841403</td>\n",
       "      <td>0.322212</td>\n",
       "      <td>0.092942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555685</td>\n",
       "      <td>0.529454</td>\n",
       "      <td>-1.008608</td>\n",
       "      <td>0.999209</td>\n",
       "      <td>0.566584</td>\n",
       "      <td>0.498463</td>\n",
       "      <td>-1.007327</td>\n",
       "      <td>0.998935</td>\n",
       "      <td>0.574179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254666</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>0.622472</td>\n",
       "      <td>1.127502</td>\n",
       "      <td>0.090205</td>\n",
       "      <td>0.050027</td>\n",
       "      <td>0.537167</td>\n",
       "      <td>1.106791</td>\n",
       "      <td>0.104683</td>\n",
       "      <td>0.056935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555509</td>\n",
       "      <td>0.528442</td>\n",
       "      <td>-1.016353</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>0.566282</td>\n",
       "      <td>0.496054</td>\n",
       "      <td>-1.003780</td>\n",
       "      <td>0.998881</td>\n",
       "      <td>0.573874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340863</td>\n",
       "      <td>0.034085</td>\n",
       "      <td>0.609426</td>\n",
       "      <td>1.111233</td>\n",
       "      <td>0.190138</td>\n",
       "      <td>0.048348</td>\n",
       "      <td>0.543935</td>\n",
       "      <td>1.086764</td>\n",
       "      <td>0.188833</td>\n",
       "      <td>0.052818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555629</td>\n",
       "      <td>0.493358</td>\n",
       "      <td>-1.004880</td>\n",
       "      <td>0.999212</td>\n",
       "      <td>0.566432</td>\n",
       "      <td>0.456661</td>\n",
       "      <td>-0.993602</td>\n",
       "      <td>0.998864</td>\n",
       "      <td>0.574027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370743</td>\n",
       "      <td>0.032656</td>\n",
       "      <td>0.630245</td>\n",
       "      <td>0.943667</td>\n",
       "      <td>0.255876</td>\n",
       "      <td>0.049792</td>\n",
       "      <td>0.539013</td>\n",
       "      <td>0.959680</td>\n",
       "      <td>0.253657</td>\n",
       "      <td>0.050928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555848</td>\n",
       "      <td>0.480916</td>\n",
       "      <td>-0.975993</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>0.566521</td>\n",
       "      <td>0.444112</td>\n",
       "      <td>-0.960663</td>\n",
       "      <td>0.998798</td>\n",
       "      <td>0.574064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349965</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>0.634341</td>\n",
       "      <td>0.967916</td>\n",
       "      <td>0.298365</td>\n",
       "      <td>0.049268</td>\n",
       "      <td>0.525557</td>\n",
       "      <td>0.979393</td>\n",
       "      <td>0.246581</td>\n",
       "      <td>0.051493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        z1        v1        x2        y2  \\\n",
       "0    0.0  0.559477  0.801142 -0.923527  0.999172  0.570418  0.778712   \n",
       "1    0.0  0.555685  0.529454 -1.008608  0.999209  0.566584  0.498463   \n",
       "2    0.0  0.555509  0.528442 -1.016353  0.999207  0.566282  0.496054   \n",
       "3    0.0  0.555629  0.493358 -1.004880  0.999212  0.566432  0.456661   \n",
       "4    0.0  0.555848  0.480916 -0.975993  0.999225  0.566521  0.444112   \n",
       "\n",
       "         z2        v2        x3  ...       z31       v31       x32       y32  \\\n",
       "0 -0.921206  0.999481  0.578074  ...  0.304162  0.063764  0.549590  0.864951   \n",
       "1 -1.007327  0.998935  0.574179  ...  0.254666  0.036302  0.622472  1.127502   \n",
       "2 -1.003780  0.998881  0.573874  ...  0.340863  0.034085  0.609426  1.111233   \n",
       "3 -0.993602  0.998864  0.574027  ...  0.370743  0.032656  0.630245  0.943667   \n",
       "4 -0.960663  0.998798  0.574064  ...  0.349965  0.033995  0.634341  0.967916   \n",
       "\n",
       "        z32       v32       x33       y33       z33       v33  \n",
       "0  0.326376  0.081902  0.595412  0.841403  0.322212  0.092942  \n",
       "1  0.090205  0.050027  0.537167  1.106791  0.104683  0.056935  \n",
       "2  0.190138  0.048348  0.543935  1.086764  0.188833  0.052818  \n",
       "3  0.255876  0.049792  0.539013  0.959680  0.253657  0.050928  \n",
       "4  0.298365  0.049268  0.525557  0.979393  0.246581  0.051493  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('coords.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class',axis=1) # features\n",
    "Y = df['class'] # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Pipelining the Model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines\n",
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(),LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(),RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(),RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(),GradientBoostingClassifier())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo,pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train,Y_train)\n",
    "    fit_models[algo] = model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and Serialize the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9777777777777777 1.0 0.9411764705882353\n",
      "rc 0.9777777777777777 1.0 0.9411764705882353\n",
      "rf 0.9777777777777777 1.0 0.9411764705882353\n",
      "gb 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for algo,model in fit_models.items():\n",
    "    Y_pred = model.predict(X_test)\n",
    "    print(algo,accuracy_score(Y_test.values,Y_pred),\n",
    "          precision_score(Y_test.values,Y_pred,average='binary',pos_label=1), #pos label is 1 (up)\n",
    "          recall_score(Y_test.values,Y_pred,average='binary',pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = fit_models['rf'].predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deadlift.pkl','wb') as f:\n",
    "    pickle.dump(fit_models['rf'],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Detections with the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deadlift.pkl','rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "counter = 0\n",
    "current_Stage = ''\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor it back\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw Landmarks\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS\n",
    "                                  , mp_drawing.DrawingSpec(color=(245,117,66),thickness=2,circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230),thickness=2,circle_radius=2))\n",
    "        \n",
    "        try:\n",
    "            row = np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "            X = pd.DataFrame([row],columns=landmarks[1:])\n",
    "            bodylang_prob = model.predict_proba(X)[0]\n",
    "            bodylang_class = model.predict(X)[0]\n",
    "            \n",
    "            if bodylang_class==0.0 and bodylang_prob[bodylang_prob.argmax()] > 0.7:\n",
    "                current_Stage = \"down\"\n",
    "            elif bodylang_class==1.0 and current_Stage==\"down\" and bodylang_prob[bodylang_prob.argmax()] > 0.7:\n",
    "                current_Stage = \"up\"\n",
    "                counter+=1\n",
    "\n",
    "            # Get status box\n",
    "            cv2.rectangle(image,(0,0),(250,60),(245,117,16),-1)\n",
    "\n",
    "            # Display Class\n",
    "            cv2.putText(image,'Class',\n",
    "                        (95,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "            if bodylang_class==0.0:\n",
    "                cv2.putText(image,\"DOWN\",\n",
    "                            (90,40),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "            elif bodylang_class==1.0:\n",
    "                cv2.putText(image,\"UP\",\n",
    "                            (90,40),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "            # Display Probability\n",
    "            cv2.putText(image,'Prob',\n",
    "                        (15,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "            cv2.putText(image,str(round(bodylang_prob[np.argmax(bodylang_prob)],2)),\n",
    "                        (10,40),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "            # Display Count\n",
    "            cv2.putText(image,'Count',\n",
    "                        (180,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "            cv2.putText(image,str(counter),\n",
    "                        (200,40),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.imshow('Deadlifts',image)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass   \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
